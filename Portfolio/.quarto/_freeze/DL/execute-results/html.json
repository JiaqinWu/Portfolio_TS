{
  "hash": "466f0222d68e6f8f636cd45527884fa4",
  "result": {
    "markdown": "---\ntitle: \"Deep Learning for Time Series\"\nformat:\n  html:\n    code-fold: true\njupyter: python3\nengine: knitr\n---\n\n::: {.cell}\n\n:::\n\n\n# 1. Introduction\nWithin this analysis, I will delve into forecasting time series data through the lens of deep learning. Specifically, I will explore and apply the nuances of Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs), and Long Short-Term Memory networks (LSTMs). These advanced models will be meticulously evaluated against traditional approaches, namely ARMA, ARIMA, and SARIMA models, to discern their predictive prowess and applicability in time series analysis. This comparative study aims to illuminate the strengths and potential trade-offs between the deep learning methodologies and more conventional statistical models.\n\n# 2. Data Visualization\n\n\n::: {.cell}\n\n:::\n\n\nIn our session, we would not fit all the datasets since the complexity of the datasets, but we want to mainly focus on three datasets, one is the vaccination rate, and others are the confirmed case number and death case number to see the future trend of these three variables.\n\n::: panel-tabset\n### Vaccination Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport plotly.express as px\nimport nbformat\n\nfig = px.line(monthly_vac, x='date', y=\"daily_vaccinations_per_million\")\nfig.update_layout(\n        xaxis_title='Time',\n        yaxis_title='Daily COVID-19 Vaccination Number',\n        title='Daily COVID-19 Vaccination Number in the US Over Time'\n    )\n```\n\n::: {.cell-output-display}\n```{=html}\n<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.31.1.min.js\"></script>                <div id=\"0f69fc0d-e480-4dc3-bd37-a110e0691c74\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0f69fc0d-e480-4dc3-bd37-a110e0691c74\")) {                    Plotly.newPlot(                        \"0f69fc0d-e480-4dc3-bd37-a110e0691c74\",                        [{\"hovertemplate\":\"date=%{x}\\u003cbr\\u003edaily_vaccinations_per_million=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\",\"2021-04-01T00:00:00\",\"2021-05-01T00:00:00\",\"2021-06-01T00:00:00\",\"2021-07-01T00:00:00\",\"2021-08-01T00:00:00\",\"2021-09-01T00:00:00\",\"2021-10-01T00:00:00\",\"2021-11-01T00:00:00\",\"2021-12-01T00:00:00\",\"2022-01-01T00:00:00\",\"2022-02-01T00:00:00\",\"2022-03-01T00:00:00\",\"2022-04-01T00:00:00\",\"2022-05-01T00:00:00\",\"2022-06-01T00:00:00\",\"2022-07-01T00:00:00\",\"2022-08-01T00:00:00\",\"2022-09-01T00:00:00\",\"2022-10-01T00:00:00\",\"2022-11-01T00:00:00\",\"2022-12-01T00:00:00\",\"2023-01-01T00:00:00\",\"2023-02-01T00:00:00\",\"2023-03-01T00:00:00\",\"2023-04-01T00:00:00\",\"2023-05-01T00:00:00\"],\"xaxis\":\"x\",\"y\":[594.4545454545455,3317.0651041666665,5045.810874704492,7039.031200423056,8436.92349726776,5238.280803807509,2909.8661202185795,1882.0777366472767,2187.3733474352193,2216.248087431694,2549.207826546801,3927.4431693989072,4512.337387625595,3155.3622421998944,1700.9473067915692,1036.7292437863564,1353.1158469945356,1215.8535166578529,879.0371584699453,846.0428344791115,764.7588577472237,1055.877049180328,1937.4658910629296,1490.683606557377,964.0190375462718,637.1359069275516,325.64812646370024,232.96774193548387,208.9256830601093,256.91147540983604],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Daily COVID-19 Vaccination Number\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Daily COVID-19 Vaccination Number in the US Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n```\n:::\n\n```{.python .cell-code}\n#fig.show()\n```\n:::\n\n\n### Confirmed Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfig = px.line(monthly_cases, x='date', y=\"cases\")\nfig.update_layout(\n        xaxis_title='Time',\n        yaxis_title='Daily COVID-19 Confimed Number',\n        title='Daily COVID-19 Confimed Number in the US Over Time'\n    )\n```\n\n::: {.cell-output-display}\n```{=html}\n<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.31.1.min.js\"></script>                <div id=\"8655d603-10f8-4064-b585-af1c145d96ce\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8655d603-10f8-4064-b585-af1c145d96ce\")) {                    Plotly.newPlot(                        \"8655d603-10f8-4064-b585-af1c145d96ce\",                        [{\"hovertemplate\":\"date=%{x}\\u003cbr\\u003ecases=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\",\"2021-04-01T00:00:00\",\"2021-05-01T00:00:00\",\"2021-06-01T00:00:00\",\"2021-07-01T00:00:00\",\"2021-08-01T00:00:00\",\"2021-09-01T00:00:00\",\"2021-10-01T00:00:00\",\"2021-11-01T00:00:00\",\"2021-12-01T00:00:00\",\"2022-01-01T00:00:00\",\"2022-02-01T00:00:00\",\"2022-03-01T00:00:00\",\"2022-04-01T00:00:00\",\"2022-05-01T00:00:00\",\"2022-06-01T00:00:00\",\"2022-07-01T00:00:00\",\"2022-08-01T00:00:00\",\"2022-09-01T00:00:00\",\"2022-10-01T00:00:00\",\"2022-11-01T00:00:00\",\"2022-12-01T00:00:00\",\"2023-01-01T00:00:00\",\"2023-02-01T00:00:00\",\"2023-03-01T00:00:00\",\"2023-04-01T00:00:00\",\"2023-05-01T00:00:00\",\"2023-06-01T00:00:00\",\"2023-07-01T00:00:00\"],\"xaxis\":\"x\",\"y\":[7619,5612,1247715,19804292,45556994,65810723,113408298,166673205,198058138,249434615,337526975,524738063,724340896,763591262,902051444,929252645,1003054388,986820811,1040470621,1127283071,1221618046,1361513056,1388730787,1546095737,2002008991,2124230911,2407222542,2359132367,2498135760,2504082662,2686554904,2785327303,2759012882,2887889320,2822828001,2952855485,2995109357,2733949911,3057181512,2972315643,2782324429,1890671296,2290153852],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Daily COVID-19 Confimed Number\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Daily COVID-19 Confimed Number in the US Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n```\n:::\n\n```{.python .cell-code}\n#fig.show()\n```\n:::\n\n\n### Death Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfig = px.line(monthly_deaths, x='date', y=\"deaths\")\nfig.update_layout(\n        xaxis_title='Time',\n        yaxis_title='Daily COVID-19 Death Number',\n        title='Daily COVID-19 Death Number in the US Over Time'\n    )\n```\n\n::: {.cell-output-display}\n```{=html}\n<div>                        <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.31.1.min.js\"></script>                <div id=\"1f2da128-2645-458c-b65a-3469c569610d\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1f2da128-2645-458c-b65a-3469c569610d\")) {                    Plotly.newPlot(                        \"1f2da128-2645-458c-b65a-3469c569610d\",                        [{\"hovertemplate\":\"date=%{x}\\u003cbr\\u003edeaths=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"2020-01-01T00:00:00\",\"2020-02-01T00:00:00\",\"2020-03-01T00:00:00\",\"2020-04-01T00:00:00\",\"2020-05-01T00:00:00\",\"2020-06-01T00:00:00\",\"2020-07-01T00:00:00\",\"2020-08-01T00:00:00\",\"2020-09-01T00:00:00\",\"2020-10-01T00:00:00\",\"2020-11-01T00:00:00\",\"2020-12-01T00:00:00\",\"2021-01-01T00:00:00\",\"2021-02-01T00:00:00\",\"2021-03-01T00:00:00\",\"2021-04-01T00:00:00\",\"2021-05-01T00:00:00\",\"2021-06-01T00:00:00\",\"2021-07-01T00:00:00\",\"2021-08-01T00:00:00\",\"2021-09-01T00:00:00\",\"2021-10-01T00:00:00\",\"2021-11-01T00:00:00\",\"2021-12-01T00:00:00\",\"2022-01-01T00:00:00\",\"2022-02-01T00:00:00\",\"2022-03-01T00:00:00\",\"2022-04-01T00:00:00\",\"2022-05-01T00:00:00\",\"2022-06-01T00:00:00\",\"2022-07-01T00:00:00\",\"2022-08-01T00:00:00\",\"2022-09-01T00:00:00\",\"2022-10-01T00:00:00\",\"2022-11-01T00:00:00\",\"2022-12-01T00:00:00\",\"2023-01-01T00:00:00\",\"2023-02-01T00:00:00\",\"2023-03-01T00:00:00\",\"2023-04-01T00:00:00\",\"2023-05-01T00:00:00\",\"2023-06-01T00:00:00\",\"2023-07-01T00:00:00\"],\"xaxis\":\"x\",\"y\":[10,65,21292,986867,2690505,3500446,4384726,5353904,5924940,6787223,7504108,9709000,12646608,13840585,16757021,16966911,18101058,17915298,18771138,19335535,20053906,22320429,22766257,24720683,26308932,25706093,29860197,29450699,30801675,30094527,31434016,31822937,31169147,32534750,31702255,33005268,33305926,30415233,33927057,32982230,30838450,20962253,25392332],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Time\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Daily COVID-19 Death Number\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Daily COVID-19 Death Number in the US Over Time\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n```\n:::\n\n```{.python .cell-code}\n#fig.show()\n```\n:::\n\n\n:::\n\n# 3. Split Data & Normalize\n\nIn the next phase of analysis, I will partition the datasets into training and testing subsets to facilitate model evaluation and validation. Given the wide range of variable scales present in the original data, I will implement **normalization** techniques on the regression values. This step is crucial for optimizing model performance by ensuring that the data conforms to a uniform scale, thereby enhancing the accuracy and effectiveness of the predictive models.\n\n::: panel-tabset\n### Vaccination Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef get_train_test(data, split_percent = 0.8):\n    # Convert data to array\n    data = np.array(data)\n    \n    # Normalize data\n    data=(data-np.mean(data,axis=0))/np.std(data,axis=0)\n    \n    # define split point for splitting data into training and testing\n    n = len(data)\n    split = int(n*split_percent)\n    train_data = data[range(split)]\n    test_data = data[split:]\n    \n    # return the test splits\n    return train_data, test_data\n\nvac_train_data, vac_test_data = get_train_test(monthly_vac['daily_vaccinations_per_million'])\n\nprint(f'Original shape: {len(monthly_vac[\"daily_vaccinations_per_million\"])}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal shape: 30\n```\n:::\n\n```{.python .cell-code}\nprint(f'Train shape: {vac_train_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (24,)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {vac_test_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (6,)\n```\n:::\n\n```{.python .cell-code}\n\nt1 = [*range(0, len(vac_train_data))]\nt2 = len(vac_train_data) + np.array([*range(0, len(vac_test_data))])\n\ndef plotly_plot(t, y, title = \"Plot\", x_label = \"Time (Month)\", y_label = \"Value\"):\n\n    \n    fig = px.line(x = t[0], y = y[0], title = title, render_mode = 'SVG')  \n    \n    # Plot the scatter points\n    for i in range(1,len(y)):\n        fig.add_scatter(x = t[i], y = y[i], mode='lines')\n    \n    # update the layout with labels and customization\n    fig.update_layout(\n        xaxis_title = x_label,\n        yaxis_title = y_label,\n        showlegend = False\n    )\n    # show the figure\n    fig.show()\n\nplotly_plot([t1, t2], [vac_train_data, vac_test_data], title = \"Vaccination Train & Test Data\")\n```\n:::\n\n\n### Confirmed Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncase_train_data, case_test_data = get_train_test(monthly_cases['cases'])\n\nprint(f'Original shape: {len(monthly_cases[\"cases\"])}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal shape: 43\n```\n:::\n\n```{.python .cell-code}\nprint(f'Train shape: {case_train_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (34,)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {case_test_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (9,)\n```\n:::\n\n```{.python .cell-code}\n\nt1 = [*range(0, len(case_train_data))]\nt2 = len(case_train_data) + np.array([*range(0, len(case_test_data))])\n\nplotly_plot([t1, t2], [case_train_data, case_test_data], title = \"Confirmed Case Train & Test Data\")\n```\n:::\n\n\n### Death Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndeath_train_data, death_test_data = get_train_test(monthly_deaths['deaths'])\n\nprint(f'Original shape: {len(monthly_deaths[\"deaths\"])}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOriginal shape: 43\n```\n:::\n\n```{.python .cell-code}\nprint(f'Train shape: {death_train_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (34,)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {death_test_data.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (9,)\n```\n:::\n\n```{.python .cell-code}\n\nt1 = [*range(0, len(death_train_data))]\nt2 = len(death_train_data) + np.array([*range(0, len(death_test_data))])\n\nplotly_plot([t1, t2], [death_train_data, death_test_data], title = \"Death Case Train & Test Data\")\n```\n:::\n\n\n:::\n\n\n# 4. Mini-Batching\n\nTo enhance the efficacy of the training process, I will incorporate the use of mini-batching. This approach involves updating the gradients more frequently within each epoch, which is expected to significantly improve the overall performance of the model. By doing so, the model can learn more effectively and adaptively from smaller subsets of data, leading to more accurate and robust predictions.\n\n::: panel-tabset\n### Vaccination Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef form_arrays(x,lookback=3,delay=1,step=1,feature_columns=[0],target_columns=[0],unique=False,verbose=False):\n  # Initialize\n  i_start=0\n  count=0\n  x_out=[]\n  y_out=[]\n  # Sequentially build mini-batches\n  while i_start + lookback + delay < x.shape[0]:\n    i_stop = i_start + lookback\n    i_pred = i_stop + delay\n    # report if desired\n    if verbose and count < 2:\n      print(\"indice range:\",i_start, i_stop, \"-->\",i_pre)\n    # define arrays\n    indices_to_keep = []\n    j = i_stop\n    while j >= i_start:\n      indices_to_keep.append(j)\n      j -= step\n    # create mini-batch sample\n    xtmp = x[indices_to_keep,:]\n    xtmp = xtmp[:,feature_columns]\n    ytmp=x[i_pred,target_columns]\n    x_out.append(xtmp)\n    y_out.append(ytmp)\n    # report if desired\n    if verbose and count <2:\n      print(xtmp, \"-->\", ytmp)\n      print(\"shape:\", xtmp.shape, \"-->\",ytmp.shape)\n    # plot\n    if verbose and count <2:\n      fig, ax = plt.subplots()\n      ax.plot(x, 'b-')\n      ax.plot(x,'bx')\n      ax.plot(indices_to_keep, xtmp, 'go')\n      ax.plot(i_pred*np.ones(len(target_columns)),ytmp, 'ro')\n      plt.show()\n    # update start point\n    if unique:\n      i_start += lookback\n    else:\n      i_start += 1\n    count += 1\n  return np.array(x_out), np.array(y_out)\n\ntrain = vac_train_data.reshape(vac_train_data.shape[0],1)\ntest = vac_test_data.reshape(vac_test_data.shape[0],1)\n\nvac_trainX, vac_trainY = form_arrays(train,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\nvac_testX, vac_testY = form_arrays(test,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\n\nprint(f'Train shape: {vac_trainX.shape} , {vac_trainY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (21, 3, 1) , (21, 1)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {vac_testX.shape} , {vac_testY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (3, 3, 1) , (3, 1)\n```\n:::\n:::\n\n\n### Confirmed Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntrain = case_train_data.reshape(case_train_data.shape[0],1)\ntest = case_test_data.reshape(case_test_data.shape[0],1)\n\ncase_trainX, case_trainY = form_arrays(train,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\ncase_testX, case_testY = form_arrays(test,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\n\nprint(f'Train shape: {case_trainX.shape} , {case_trainY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (31, 3, 1) , (31, 1)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {case_testX.shape} , {case_testY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (6, 3, 1) , (6, 1)\n```\n:::\n:::\n\n\n### Death Case Number\n\n\n::: {.cell}\n\n```{.python .cell-code}\ntrain = death_train_data.reshape(death_train_data.shape[0],1)\ntest = death_test_data.reshape(death_test_data.shape[0],1)\n\ndeath_trainX, death_trainY = form_arrays(train,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\ndeath_testX, death_testY = form_arrays(test,lookback=2, delay=1, step=1, feature_columns=[0], target_columns=[0], unique=False,verbose=False)\n\nprint(f'Train shape: {death_trainX.shape} , {death_trainY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTrain shape: (31, 3, 1) , (31, 1)\n```\n:::\n\n```{.python .cell-code}\nprint(f'Test shape: {death_testX.shape} , {death_testY.shape}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTest shape: (6, 3, 1) , (6, 1)\n```\n:::\n:::\n\n\n:::\n\n\n# 5. RNN\n\nIn this section, I will focus on training a Recurrent Neural Network (RNN), which is specifically engineered for handling sequential data by utilizing cyclic connections that retain memory of prior inputs. To enhance the robustness and generalizability of the RNN, I plan to train it both with and without regularization techniques. To streamline this process, I will encapsulate the modeling code within a single function that accepts parameters for data, model type, and a boolean indicating whether regularization should be applied. This modular approach will facilitate easy adjustments and retesting under various configurations, improving efficiency and experimental flexibility.\n\nHere is how we define each function to generate the model:\n\n::: {.cell}\n\n```{.python .cell-code}\nimport tensorflow as tf\n# Utility functions \ndef regression_report(yt,ytp,yv,yvp):\n  print(\"--------- Regression Report ---------\")\n  print(\"TRAINING:\")\n  train_mse = np.mean((yt - ytp) ** 2)\n  train_mae = np.mean(np.abs(yt - ytp))\n  print(\"MSE\", train_mse)\n  print(\"MAE\", train_mae)\n  \n  # PARITY PLOT\n  fig, ax = plt.subplots()\n  ax.plot(yt, ytp, 'ro')\n  ax.plot(yt, yt, 'b-')\n  ax.set(xlabel='y_data', ylabel='y_predicted',\n        title = 'Training data parity plot (line y=x represents a perfect fit)')\n  plt.show()\n  \n  # PLOT PART OF THE PREDICTED TIME-SERIES\n  frac_plot=1.0\n  upper=int(frac_plot*yt.shape[0]);\n  fig, ax = plt.subplots()\n  ax.plot(yt[0:upper], 'b-')\n  ax.plot(ytp[0:upper], 'r-', alpha=0.5)\n  ax.plot(ytp[0:upper], 'ro', alpha=0.25)\n  ax.set(xlabel='index', ylabel='y(t) (blue=actual & red=prediction)',title='Training: Time-series prediction')\n  plt.show()\n  \n  print(\"VALIDATION:\")\n  val_mse = np.mean((yv - yvp) ** 2)\n  val_mae = np.mean(np.abs(yv - yvp))\n  print(\"MSE\", val_mse)\n  print(\"MAE\", val_mae)\n  \n  # PARITY PLOT\n  fig,ax = plt.subplots()\n  ax.plot(yv,yvp, 'ro')\n  ax.plot(yv, yv,'b-')\n  ax.set(xlabel='y_data', ylabel='y_predicted',title='Validation data parity plot (line y=x represents a perfect fit)')\n  \n  # PLOT PART OF THE PREDICTED TIME-SERIES\n  upper=int(frac_plot*yv.shape[0])\n  fig,ax = plt.subplots()\n  ax.plot(yv[0:upper], 'b-')\n  ax.plot(yvp[0:upper], 'r-', alpha=0.5)\n  ax.plot(yvp[0:upper], 'ro', alpha=0.25)\n  ax.set(xlabel='index', ylabel='y(t) (blue=actual & red=prediction)',title='Validation: Time-series prediction')\n  plt.show()\n  return train_mse, train_mae, val_mse, val_mae\n\ndef history_plot(history):\n  FS=18 #fontsize\n  history_dict = history.history\n  loss_values = history_dict['loss']\n  val_loss_values = history_dict['val_loss']\n  epochs = range(1, len(loss_values) + 1)\n  plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n  plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n  plt.title('Training and Validation Loss')\n  plt.xlabel('Epochs')\n  plt.ylabel('Loss')\n  plt.ylim(bottom=0) \n  plt.legend()\n  plt.show()\n\n# Define model function\ndef train_model(model_type, train_x, train_y, val_x, val_y, regularization = True, L2=1e-4):\n  if regularization:\n    reg = regularizers.L2(L2)\n  else:\n    reg = None\n  \n  # Define parameters\n  optimizer=\"rmsprop\"\n  loss_function = 'mean_squared_error'\n  learning_rate=0.01\n  numbers_epochs=200\n  input_shape=(train_x.shape[1],train_x.shape[2])\n  train_x1 = train_x.reshape(train_x.shape[0],train_x.shape[1]*train_x.shape[2])\n  batch_size=len(train_x1)              # batch training\n  \n  # BUILD MODEL\n  recurrent_hidden_units=32\n  \n  # CREATE MODEL\n  model = keras.Sequential()\n  \n  # ADD RECURRENT LAYER\n  if model_type == 'RNN':\n    model.add(SimpleRNN(\n    units=recurrent_hidden_units,\n    return_sequences=False,\n    input_shape=input_shape, \n    # recurrent_dropout=0.8,\n    recurrent_regularizer=reg,\n    activation='relu')\n              )\n  elif model_type == 'GRU':\n    model.add(GRU(\n    units=recurrent_hidden_units,\n    return_sequences=False,\n    input_shape=input_shape, \n    # recurrent_dropout=0.8,\n    recurrent_regularizer=reg,\n    activation='relu')\n              ) \n  elif model_type == 'LSTM':\n    model.add(LSTM(\n    units=recurrent_hidden_units,\n    return_sequences=False,\n    input_shape=input_shape, \n    # recurrent_dropout=0.8,\n    recurrent_regularizer=reg,\n    activation='relu')\n              )\n  else:\n    print('Wrong model type')\n  \n  # NEED TO TAKE THE OUTPUT RNN AND CONVERT TO SCALAR \n  model.add(Dense(units=1, activation='linear'))\n  \n  # MODEL SUMMARY\n  print(model.summary()); #print(x_train.shape,y_train.shape)  \n  \n  # COMPILING THE MODEL \n  opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n  model.compile(optimizer=opt, loss=loss_function)\n  \n  # TRAINING YOUR MODEL\n  history_techmu = model.fit(train_x,\n                      train_y,\n                      epochs=numbers_epochs,\n                      batch_size=batch_size, verbose=False,\n                      validation_data=(val_x, val_y))\n  # History plot\n  history_plot(history_techmu)\n  \n  # Predictions \n  train_pred=model.predict(train_x)\n  val_pred=model.predict(val_x) \n  train_mse, train_mae, val_mse, val_mae = regression_report(train_y,train_pred,val_y,val_pred)\n  return train_mse, train_mae, val_mse, val_mae\n```\n:::\n\n\n\n::: panel-tabset\n### Vaccination Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn (SimpleRNN)          │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.02507889151580927\nMAE 0.1149272712569786\nVALIDATION:\nMSE 0.006079864716768059\nMAE 0.07522609063899766\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-13-4.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults = []\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'RNN', 'reg': True, 'train_mse': 0.02507889151580927, 'train_mae': 0.1149272712569786, 'val_mse': 0.006079864716768059, 'val_mae': 0.07522609063899766}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-13-5.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_1\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_1 (SimpleRNN)        │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.00787940727730981\nMAE 0.06698729147534957\nVALIDATION:\nMSE 0.00920212609798102\nMAE 0.09152555238290379\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-14-11.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-14-12.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-14-13.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-14-14.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'RNN', 'reg': False, 'train_mse': 0.00787940727730981, 'train_mae': 0.06698729147534957, 'val_mse': 0.00920212609798102, 'val_mae': 0.09152555238290379}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-14-15.png){width=672}\n:::\n:::\n\n\n### Confirmed Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_2\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_2 (SimpleRNN)        │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.01208264434375932\nMAE 0.09365220881610602\nVALIDATION:\nMSE 0.287867368754712\nMAE 0.3990768925102359\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-15-21.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-15-22.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-15-23.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-15-24.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'RNN', 'reg': True, 'train_mse': 0.01208264434375932, 'train_mae': 0.09365220881610602, 'val_mse': 0.287867368754712, 'val_mae': 0.3990768925102359}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-15-25.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_3\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_3 (SimpleRNN)        │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.011068698360150505\nMAE 0.09134005644279669\nVALIDATION:\nMSE 0.28914222560102826\nMAE 0.40440739549714383\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-16-31.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-16-32.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-16-33.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-16-34.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'RNN', 'reg': False, 'train_mse': 0.011068698360150505, 'train_mae': 0.09134005644279669, 'val_mse': 0.28914222560102826, 'val_mae': 0.40440739549714383}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-16-35.png){width=672}\n:::\n:::\n\n\n### Death Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_4\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_4 (SimpleRNN)        │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.010132386133306859\nMAE 0.08203391647657629\nVALIDATION:\nMSE 0.200721501491255\nMAE 0.31593309251768603\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-17-41.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-17-42.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-17-43.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-17-44.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'RNN', 'reg': True, 'train_mse': 0.010132386133306859, 'train_mae': 0.08203391647657629, 'val_mse': 0.200721501491255, 'val_mae': 0.31593309251768603}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-17-45.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'RNN'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_5\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_5 (SimpleRNN)        │ (None, 32)             │         1,088 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 1,121 (4.38 KB)\n Trainable params: 1,121 (4.38 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.011191254598802181\nMAE 0.08335613950623097\nVALIDATION:\nMSE 0.21909917177845487\nMAE 0.3324218035569113\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-18-51.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-18-52.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-18-53.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-18-54.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'RNN', 'reg': False, 'train_mse': 0.011191254598802181, 'train_mae': 0.08335613950623097, 'val_mse': 0.21909917177845487, 'val_mae': 0.3324218035569113}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-18-55.png){width=672}\n:::\n:::\n\n\n:::\n\n\n# 6. LSTM\n\nIn this section, I will be training a Long Short-Term Memory (LSTM) network, a specialized form of Recurrent Neural Network (RNN). LSTMs are designed to overcome the vanishing gradient problem inherent in traditional RNNs through a sophisticated gating mechanism. This mechanism effectively regulates the information flow into and out of the network's memory cells, facilitating the learning of long-term dependencies. I plan to evaluate the LSTM's performance both with and without the application of regularization techniques, to ascertain their impact on the model's ability to generalize.\n\n::: panel-tabset\n### Vaccination Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_6\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm (LSTM)                     │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.10949200399905415\nMAE 0.2567433805785602\nVALIDATION:\nMSE 0.045478360226215715\nMAE 0.21310756376468887\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-19-61.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-19-62.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-19-63.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-19-64.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'LSTM', 'reg': True, 'train_mse': 0.10949200399905415, 'train_mae': 0.2567433805785602, 'val_mse': 0.045478360226215715, 'val_mae': 0.21310756376468887}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-19-65.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_7\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_1 (LSTM)                   │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.07068324949798901\nMAE 0.20521890681234387\nVALIDATION:\nMSE 0.3079376817918499\nMAE 0.5525765694288786\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-20-71.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-20-72.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-20-73.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-20-74.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'LSTM', 'reg': False, 'train_mse': 0.07068324949798901, 'train_mae': 0.20521890681234387, 'val_mse': 0.3079376817918499, 'val_mae': 0.5525765694288786}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-20-75.png){width=672}\n:::\n:::\n\n\n### Confirmed Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_8\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_2 (LSTM)                   │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.010772498417440294\nMAE 0.08536091643176864\nVALIDATION:\nMSE 0.15685404893477067\nMAE 0.27687905418936576\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-21-81.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-21-82.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-21-83.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-21-84.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'LSTM', 'reg': True, 'train_mse': 0.010772498417440294, 'train_mae': 0.08536091643176864, 'val_mse': 0.15685404893477067, 'val_mae': 0.27687905418936576}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-21-85.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_9\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_3 (LSTM)                   │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (Dense)                 │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.010985848313029671\nMAE 0.08988362240819925\nVALIDATION:\nMSE 0.23687703248351913\nMAE 0.3491596388103492\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-22-91.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-22-92.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-22-93.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-22-94.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'LSTM', 'reg': False, 'train_mse': 0.010985848313029671, 'train_mae': 0.08988362240819925, 'val_mse': 0.23687703248351913, 'val_mae': 0.3491596388103492}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-22-95.png){width=672}\n:::\n:::\n\n\n### Death Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_10\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_4 (LSTM)                   │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.01200209890345945\nMAE 0.08651425714075692\nVALIDATION:\nMSE 0.19144112076395683\nMAE 0.3055604438811861\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-23-101.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-23-102.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-23-103.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-23-104.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'LSTM', 'reg': True, 'train_mse': 0.01200209890345945, 'train_mae': 0.08651425714075692, 'val_mse': 0.19144112076395683, 'val_mae': 0.3055604438811861}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-23-105.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'LSTM'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_11\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_5 (LSTM)                   │ (None, 32)             │         4,352 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 4,385 (17.13 KB)\n Trainable params: 4,385 (17.13 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.012895536589574551\nMAE 0.096573344388118\nVALIDATION:\nMSE 0.27565403360039176\nMAE 0.3741007038837445\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-24-111.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-24-112.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-24-113.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-24-114.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'LSTM', 'reg': False, 'train_mse': 0.012895536589574551, 'train_mae': 0.096573344388118, 'val_mse': 0.27565403360039176, 'val_mae': 0.3741007038837445}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-24-115.png){width=672}\n:::\n:::\n\n\n:::\n\n\n# 7. GRU\n\n::: panel-tabset\n### Vaccination Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_12\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru (GRU)                       │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_12 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.059621629644910724\nMAE 0.19088212280974756\nVALIDATION:\nMSE 0.11277090259496636\nMAE 0.3356135067451373\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-25-121.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-25-122.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-25-123.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-25-124.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'GRU', 'reg': True, 'train_mse': 0.059621629644910724, 'train_mae': 0.19088212280974756, 'val_mse': 0.11277090259496636, 'val_mae': 0.3356135067451373}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-25-125.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, vac_trainX, vac_trainY, vac_testX, vac_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_13\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru_1 (GRU)                     │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_13 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.06284618651616207\nMAE 0.20501508582688174\nVALIDATION:\nMSE 0.31607067071891154\nMAE 0.5619419194368894\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-26-131.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-26-132.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-26-133.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-26-134.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Vaccination',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Vaccination', 'model_type': 'GRU', 'reg': False, 'train_mse': 0.06284618651616207, 'train_mae': 0.20501508582688174, 'val_mse': 0.31607067071891154, 'val_mae': 0.5619419194368894}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-26-135.png){width=672}\n:::\n:::\n\n\n### Confirmed Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_14\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru_2 (GRU)                     │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_14 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.012879188038375282\nMAE 0.09812820178520207\nVALIDATION:\nMSE 0.27074395311402305\nMAE 0.3705160823744463\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-27-141.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-27-142.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-27-143.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-27-144.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'GRU', 'reg': True, 'train_mse': 0.012879188038375282, 'train_mae': 0.09812820178520207, 'val_mse': 0.27074395311402305, 'val_mae': 0.3705160823744463}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-27-145.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, case_trainX, case_trainY, case_testX, case_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_15\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru_3 (GRU)                     │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_15 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.012173408547347405\nMAE 0.08446425152752393\nVALIDATION:\nMSE 0.1706351819486199\nMAE 0.28984830963675345\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-28-151.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-28-152.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-28-153.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-28-154.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Confirmed Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Confirmed Case', 'model_type': 'GRU', 'reg': False, 'train_mse': 0.012173408547347405, 'train_mae': 0.08446425152752393, 'val_mse': 0.1706351819486199, 'val_mae': 0.28984830963675345}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-28-155.png){width=672}\n:::\n:::\n\n\n### Death Case Number\n\nI will be training the model in two distinct scenarios: with regularization and without. This dual approach will allow us to evaluate the impact of regularization techniques on model performance, particularly in terms of preventing overfitting and enhancing generalization to new data. This comparative strategy is designed to optimize and fine-tune our model's parameters for more robust predictions.\n\n#### With Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = True\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_16\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru_4 (GRU)                     │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.013954300483919\nMAE 0.10031510864130365\nVALIDATION:\nMSE 0.2970078119234108\nMAE 0.3840727000321718\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-29-161.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-29-162.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-29-163.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-29-164.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'GRU', 'reg': True, 'train_mse': 0.013954300483919, 'train_mae': 0.10031510864130365, 'val_mse': 0.2970078119234108, 'val_mae': 0.3840727000321718}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-29-165.png){width=672}\n:::\n:::\n\n\n\n#### Without Regularization\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel_type = 'GRU'\nreg = False\ntrain_mse, train_mae, val_mse, val_mae = train_model(model_type, death_trainX, death_trainY, death_testX, death_testY, regularization = reg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential_17\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ gru_5 (GRU)                     │ (None, 32)             │         3,360 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_17 (Dense)                │ (None, 1)              │            33 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n Total params: 3,393 (13.25 KB)\n Trainable params: 3,393 (13.25 KB)\n Non-trainable params: 0 (0.00 B)\nNone\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n--------- Regression Report ---------\nTRAINING:\nMSE 0.014024941900819576\nMAE 0.09984642953073165\nVALIDATION:\nMSE 0.2968673524738457\nMAE 0.38273439694302996\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-30-171.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-30-172.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-30-173.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-30-174.png){width=672}\n:::\n\n```{.python .cell-code}\nresult_dict = {\n  'data_type':'Death Case',\n  'model_type':model_type,\n  'reg':reg,\n  'train_mse':train_mse,\n  'train_mae':train_mae,\n  'val_mse':val_mse,\n  'val_mae':val_mae\n  \n}\nresults.append(result_dict)\nprint(f'Model results: {result_dict}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel results: {'data_type': 'Death Case', 'model_type': 'GRU', 'reg': False, 'train_mse': 0.014024941900819576, 'train_mae': 0.09984642953073165, 'val_mse': 0.2968673524738457, 'val_mae': 0.38273439694302996}\n```\n:::\n\n::: {.cell-output-display}\n![](DL_files/figure-html/unnamed-chunk-30-175.png){width=672}\n:::\n:::\n\n\n:::\n\n# 8. Discussion\n\n\nIn constructing our models, we design a framework tailored for RNN, LSTM, and GRU networks to tackle specific tasks. Each model begins with defining regularization practices to ensure generalization, using L2 regularization as needed. We configure the model using the RMSprop optimizer, a mean squared error loss function, and set a learning rate. Depending on the model type—RNN, GRU, or LSTM—we adjust the architecture by setting the number of recurrent hidden units and whether the model returns sequences. After assembling the model, we compile it, train it on our dataset over numerous epochs, and validate it using a separate dataset. This systematic approach allows us to fine-tune and compare the performance of each neural network architecture effectively.\n\n\n### 8.1 How do the results from the 3 different ANN models compare with each other in terms of accuracy and predictive power?\n\n::: {.cell}\n\n```{.python .cell-code}\n# Combine results into table\nresult_df = pd.DataFrame(results)\nresult_df['train_rmse'] = result_df['train_mse'].apply(lambda x: x ** .5)\nresult_df['val_rmse'] = result_df['val_mse'].apply(lambda x: x ** .5)\nresult_df[['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         data_type model_type    reg  train_rmse  val_rmse\n8   Confirmed Case       LSTM   True    0.103791  0.396048\n15  Confirmed Case        GRU  False    0.110333  0.413080\n9   Confirmed Case       LSTM  False    0.104813  0.486700\n14  Confirmed Case        GRU   True    0.113487  0.520331\n2   Confirmed Case        RNN   True    0.109921  0.536533\n3   Confirmed Case        RNN  False    0.105208  0.537719\n10      Death Case       LSTM   True    0.109554  0.437540\n4       Death Case        RNN   True    0.100660  0.448020\n5       Death Case        RNN  False    0.105789  0.468080\n11      Death Case       LSTM  False    0.113559  0.525028\n17      Death Case        GRU  False    0.118427  0.544855\n16      Death Case        GRU   True    0.118128  0.544984\n0      Vaccination        RNN   True    0.158363  0.077973\n1      Vaccination        RNN  False    0.088766  0.095928\n6      Vaccination       LSTM   True    0.330896  0.213257\n12     Vaccination        GRU   True    0.244175  0.335814\n7      Vaccination       LSTM  False    0.265863  0.554921\n13     Vaccination        GRU  False    0.250691  0.562202\n```\n:::\n:::\n\n**Best Vaccination Number DL Model:**\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Vaccination'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True).head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     data_type model_type   reg  train_rmse  val_rmse\n0  Vaccination        RNN  True    0.158363  0.077973\n```\n:::\n:::\n\n\nWe can see the best DL model for vaccination number is RNN model without regulation since it has the lowest validation RMSE value.\n\n**Best Confirmed Case DL Model:**\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Confirmed Case'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True).head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        data_type model_type   reg  train_rmse  val_rmse\n8  Confirmed Case       LSTM  True    0.103791  0.396048\n```\n:::\n:::\n\n\nWe can see the best DL model for confirmed case is RNN model without regulation since it has the lowest validation RMSE value.\n\n**Best Death Case DL Model:**\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Death Case'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True).head(1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     data_type model_type   reg  train_rmse  val_rmse\n10  Death Case       LSTM  True    0.109554   0.43754\n```\n:::\n:::\n\n\nWe can see the best DL model for death case is LSTM model with regulation since it has the lowest validation RMSE value.\n\nIn our evaluation, the RNN and LSTM models demonstrated superior performance, excelling in their predictive capabilities. Conversely, the GRU model showed relatively lower effectiveness. This divergence in performance highlights the distinct advantages and challenges associated with each type of neural network architecture, emphasizing the importance of choosing the right model based on the specific requirements and nuances of the dataset at hand.\n\n### 8.2 What effect does including regularization have on your results?\n\nRegularization is crucial in machine learning, adding a penalty to the loss function to reduce the complexity of the model, thus minimizing overfitting to the training data. This technique varies in effectiveness across different datasets. For example, an un-regularized LSTM model achieved the lowest RMSE for emissions data, while a regularized GRU model was most effective for the temperature dataset. Across various datasets, a consistent observation was a higher RMSE in the validation set compared to the training set, indicating persistent overfitting despite the regularization's attempt to bridge the gap between training and validation performance.\n\n### 8.3 How far into the future can the deep learning model accurately predict the future?\n\nDeep learning models' ability to predict future events hinges on the data they have encountered during training. These models, fundamentally supervised, learn and generate predictions based on the sequences they've been exposed to. Thus, their predictive power extends only as far as recognizing patterns similar to those within their training datasets. The farther into the future a prediction extends, the more reliant it becomes on the quality and representativeness of historical data, limiting accuracy when facing novel scenarios or trends not previously seen during training.\n\n\n### 8.4. How does your deep learning modeling compare to the traditional single-variable time-series ARMA/ARIMA models from HW-3?\n\n::: panel-tabset\n#### Vaccination Number\n\nFrom Arima model, below are the computed metrics:\n\n| Metric       | Value               |\n|--------------|---------------------|\n| ME           | -1.260901e+04       |\n| RMSE         | 4.404350e+04        |\n| MAE          | 2.961164e+04        |\n| MPE          | -1.819884e+00       |\n| MAPE         | 2.997255e+01        |\n| MASE         | 5.644007e-01        |\n| ACF1         | -1.726600e-01       |\n\nFrom Deep Learning model, below are the computed metrics:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Vaccination'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      data_type model_type    reg  train_rmse  val_rmse\n0   Vaccination        RNN   True    0.158363  0.077973\n1   Vaccination        RNN  False    0.088766  0.095928\n6   Vaccination       LSTM   True    0.330896  0.213257\n12  Vaccination        GRU   True    0.244175  0.335814\n7   Vaccination       LSTM  False    0.265863  0.554921\n13  Vaccination        GRU  False    0.250691  0.562202\n```\n:::\n:::\n\n\n#### Confirmed Case Number\n\nFrom Arima model, below are the computed metrics:\n\n| Metric       | Value               |\n|--------------|---------------------|\n| ME           | 5.887429e+04       |\n| RMSE         | 2.036015e+06        |\n| MAE          | 1.092948e+06        |\n| MPE          | 1.626543e+04       |\n| MAPE         | 1.876329e+04        |\n| MASE         | 2.083170e+01        |\n| ACF1         | 1.041066e-01       |\n\nFrom Deep Learning model, below are the computed metrics:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Confirmed Case'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         data_type model_type    reg  train_rmse  val_rmse\n8   Confirmed Case       LSTM   True    0.103791  0.396048\n15  Confirmed Case        GRU  False    0.110333  0.413080\n9   Confirmed Case       LSTM  False    0.104813  0.486700\n14  Confirmed Case        GRU   True    0.113487  0.520331\n2   Confirmed Case        RNN   True    0.109921  0.536533\n3   Confirmed Case        RNN  False    0.105208  0.537719\n```\n:::\n:::\n\n\n#### Death Case Number\n\nFrom Arima model, below are the computed metrics:\n\n| Metric       | Value               |\n|--------------|---------------------|\n| ME           | 1373.71612640       |\n| RMSE         | 8276.58694400        |\n| MAE          | 6716.48728344        |\n| MPE          | 64.68052062       |\n| MAPE         | 74.15331696         |\n| MASE         | 0.12801688        |\n| ACF1         | -0.09912142        |\n\nFrom Deep Learning model, below are the computed metrics:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nresult_df[result_df.data_type=='Death Case'][['data_type','model_type', 'reg','train_rmse','val_rmse']].sort_values(by=['data_type', 'val_rmse'], ascending=True)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     data_type model_type    reg  train_rmse  val_rmse\n10  Death Case       LSTM   True    0.109554  0.437540\n4   Death Case        RNN   True    0.100660  0.448020\n5   Death Case        RNN  False    0.105789  0.468080\n11  Death Case       LSTM  False    0.113559  0.525028\n17  Death Case        GRU  False    0.118427  0.544855\n16  Death Case        GRU   True    0.118128  0.544984\n```\n:::\n:::\n\n\n:::\n\n\nThe performance analysis shows that DL models often outperform traditional models, notably in terms of RMSE, showcasing their robustness in handling diverse datasets. However, the efficacy of these models is somewhat constrained by the size of the available data. Small datasets tend to skew performance, highlighting a potential limitation in scenarios where expansive data is not available.\n\nFor ARIMA models, their predictive capability is generally limited when dealing with noisy, fluctuating data, often producing overly simplistic forecasts. In contrast, ARIMAX and VAR models manage to capture underlying trends more effectively, albeit with some inconsistency in the presence of volatility. Deep Learning models, on the other hand, excel with larger datasets, achieving near-perfect predictions. The performance disparity underscores the importance of dataset size in leveraging the full potential of advanced DL models.\n\n\n\n# 9. Write a discussion paragraph Comparing your models (use RMSE) and forecasts from these sections with your Deep Learning Models.\n\nThis analysis has demonstrated the potent capabilities of deep learning in forecasting time series data. The efficacy of deep learning models relative to traditional approaches is challenging to evaluate directly due to discrepancies in the training and validation datasets. However, the Root Mean Square Error (RMSE) metric reveals considerably higher values for traditional time series models, implying that these models may be less adept at capturing the variability within the dataset. Conversely, deep learning models have consistently produced RMSE values under 1, suggesting superior performance in tracking the actual data trends.\n\nA closer inspection of the training and validation performance of deep learning models against the actual forecasts from traditional models, like ARIMA, underscores this contrast. The ARIMA models, despite their sophistication, often faltered in accounting for the dataset's inherent variance. In contrast, deep learning models demonstrated an ability to assimilate and reflect this variance in their predictions. Notably, the hierarchy of deep learning model performance typically favored the GRU, followed by the LSTM, and then the RNN, aligning with the evolutionary complexity of these architectures.\n\nTraditional time series models necessitate transforming data into a stationary form, with consistent mean and variance, to make accurate extrapolations. This often involves processes such as differencing, which may not always be sufficient for effective forecasting. On the other hand, deep learning models function as universal approximators, capable of modeling any form of data variance. This attribute renders them particularly suitable for complex time series datasets characterized by pronounced fluctuations and seasonal variations, enabling them to deliver more accurate and robust forecasts.\n\n\n",
    "supporting": [
      "DL_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}